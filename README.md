<h1>Next-Word Prediction and Text Generation</h1>

**Overview**

This project focuses on next-word prediction and text generation using a neural network model trained on a dataset. While the model is not highly accurate yet due to limited training, it demonstrates the capability of generating probable next words based on input sequences.

**Dataset**

The model is trained on a dataset sourced from the lutzhamel/fake-news GitHub repository. The dataset consists of text data that helps in training the model to recognize and predict word sequences.

**Features**

Next-word prediction: Given an input sequence, the model attempts to predict the next word.

Text generation: The model can generate a sequence of words based on an initial input phrase.

**Limitations**

The model has not been extensively trained and currently lacks high accuracy.

Predictions may not be grammatically or contextually correct.

Additional training and hyperparameter tuning are needed for improvement.

**Files**

*main.ipynb* - Contains the Jupyter Notebook with the code for training and testing the model.

*fake_or_real.csv* - The dataset used for training the model.

**Acknowledgments**

Special thanks to:

lutzhamel/fake-news and the NeuralNine YouTube Channel for their resources in building this project.

**Usage**

To run the project, execute main.ipynb in Jupyter Notebook and experiment with input phrases for next-word prediction and text generation.
