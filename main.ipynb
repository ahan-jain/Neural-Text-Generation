{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14d76f60-52bf-44de-b680-766edcbcffc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Activation\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1061d699-9971-41ed-8ded-1288168ecf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = pd.read_csv(\"Text-Gen/fake_or_real.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dddb1f4-8fc2-41f8-a636-51773adf92e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = list(text_data.text.values)\n",
    "combined_text = \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a45527bc-1cf5-4b65-ac3e-f61e90ccf804",
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_text = combined_text[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cd2b966-067b-419a-b888-bb255c512dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "tokens = tokenizer.tokenize(partial_text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7626001d-2be2-45e3-a743-6d47cf5d71a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique_tokens = np.unique(tokens)\n",
    "unique_token_index = {token : idx for idx, token in enumerate(unique_tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "577ac55f-0084-4650-9ed8-bacbed18dc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_words = 10\n",
    "input = []\n",
    "next_words = []\n",
    "\n",
    "for i in range(len(tokens) - initial_words):\n",
    "    input.append(tokens[i:i + initial_words])\n",
    "    next_words.append(tokens[i + initial_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c11089b-df48-4714-87a5-eaa6327ace30",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(input), initial_words, len(unique_tokens)), dtype=bool)\n",
    "y = np.zeros((len(next_words), len(unique_tokens)), dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a16bd497-e20d-441a-818a-d93ecb16ebf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, words in enumerate(input):\n",
    "    for j, word in enumerate(words):\n",
    "        X[i, j, unique_token_index[word]] = 1\n",
    "    y[i, unique_token_index[next_words[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bafbc3e9-907c-4665-bb7f-66e7d09f77e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(initial_words, len(unique_tokens)), return_sequences=True))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(len(unique_tokens)))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2128f81-ec3b-402c-a516-670171c58ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.0398 - loss: 6.3113 \n",
      "Epoch 2/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0620 - loss: 5.8205\n",
      "Epoch 3/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0723 - loss: 5.7085\n",
      "Epoch 4/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0658 - loss: 5.7260\n",
      "Epoch 5/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0606 - loss: 5.7507\n",
      "Epoch 6/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0600 - loss: 5.6693\n",
      "Epoch 7/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0649 - loss: 5.5991\n",
      "Epoch 8/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0585 - loss: 5.6085\n",
      "Epoch 9/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0523 - loss: 5.5013\n",
      "Epoch 10/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0730 - loss: 5.2874\n",
      "Epoch 11/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0735 - loss: 5.1423\n",
      "Epoch 12/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0849 - loss: 4.9306\n",
      "Epoch 13/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1062 - loss: 4.6667\n",
      "Epoch 14/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1062 - loss: 4.5033\n",
      "Epoch 15/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1498 - loss: 4.1262\n",
      "Epoch 16/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1631 - loss: 3.8264\n",
      "Epoch 17/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2100 - loss: 3.4746\n",
      "Epoch 18/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.2917 - loss: 3.0756\n",
      "Epoch 19/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.3572 - loss: 2.7559\n",
      "Epoch 20/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4126 - loss: 2.4513\n",
      "Epoch 21/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5086 - loss: 2.1412\n",
      "Epoch 22/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6311 - loss: 1.7488\n",
      "Epoch 23/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7478 - loss: 1.4144\n",
      "Epoch 24/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8251 - loss: 1.1188\n",
      "Epoch 25/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8632 - loss: 0.9116\n",
      "Epoch 26/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9174 - loss: 0.7016\n",
      "Epoch 27/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9582 - loss: 0.4735\n",
      "Epoch 28/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9451 - loss: 0.5038\n",
      "Epoch 29/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9809 - loss: 0.2916\n",
      "Epoch 30/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9683 - loss: 0.2989\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x16a70d1f0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=RMSprop(learning_rate=0.01), metrics = [\"accuracy\"])\n",
    "model.fit(X, y, batch_size=128, epochs = 30, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c23fad-197c-49ea-bb8c-284ec0d53ee7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca2952de-b15e-45f5-9228-fde11667f0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"text_gen_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00c7ebe1-e99d-4d9b-9abd-252de74a443d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"text_gen_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f3bffbc-a9b0-4549-a5af-9da3a947efcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_word(input, best):\n",
    "    input = input.lower()\n",
    "    X = np.zeros((1, initial_words, len(unique_tokens)))\n",
    "    for i, word in enumerate(input.split()):\n",
    "        X[0, i, unique_token_index[word]] = 1\n",
    "\n",
    "    predictions = model.predict(X)[0]\n",
    "    return np.argpartition(predictions, -best)[-best:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6819f361-5758-4a86-bef9-e3a5f97bbb69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n"
     ]
    }
   ],
   "source": [
    "possible = predict_next_word(\"He will have to look into this thing and he\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "196babaf-71c5-4594-8a39-760ab7f761a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['really', 'many', 'gone', 'not', 'be']\n"
     ]
    }
   ],
   "source": [
    "print([unique_tokens[idx] for idx in possible])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c64d564f-2b55-4d41-9d7c-71ab21c2c8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(input, length, choices=3):\n",
    "    sequence = input.split()\n",
    "    current_pos = 0\n",
    "    for i in range(length):\n",
    "        sub_sequence = \" \".join(tokenizer.tokenize(\" \".join(sequence).lower())[current_pos:current_pos+initial_words])\n",
    "        try:\n",
    "            choice = unique_tokens[random.choice(predict_next_word(sub_sequence, creativity))]\n",
    "        except:\n",
    "            choice = random.choice(unique_tokens)\n",
    "        sequence.append(choice)\n",
    "        current_pos+=1\n",
    "    return \" \".join(sequence)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4913d0d1-55eb-4db3-a2d2-5803f23c5b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to see what is possible in this world circulated spinmeisters re thought them up film final unapologetic https paranoid their careers very rating went pro away director make'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(\"I want to see what is possible in this world\", 20, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8c5b19-1da7-4ffb-8a05-3d40fe385260",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
